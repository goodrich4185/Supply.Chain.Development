---
title: "Environment"
author: "Ryan Goodrich"
date: "August 31, 2014"
output: html_document
runtime: shiny
---
```{r Loading required packages}
required_packages<-c("raster","plyr","doParallel","rgdal")
num_packages<-length(required_packages)
for(i in 1:num_packages){
  if((required_packages[[i]] %in% rownames(installed.packages()))=="FALSE"){install.packages(required_packages[[i]])}
}

require(raster)
require(plyr)
require(doParallel)
require(rgdal)

rm(required_packages)
rm(num_packages)
rm(i)
```

```{r Importing NASS CDL files and raster creation}
#County raster files
Worth_2011_file<-'TIFF Images/Worth_2011.tif'
Worth_2012_file<-'TIFF Images/Worth_2012.tif'
Worth_2013_file<-'TIFF Images/Worth_2013.tif'

Worth_2011<-raster(Worth_2011_file)
rm(Worth_2011_file)
Worth_2012=raster(Worth_2012_file)
rm(Worth_2012_file)
Worth_2013=raster(Worth_2013_file)
rm(Worth_2013_file)
```

```{r Function to recode rasters}
f.recode=function(raster){
  raster[is.na(raster)]<-0
  raster[(raster==2)|(raster==3)|(raster==4)|(raster==6)|(raster==10)|(raster==11)|(raster==14)|(raster==21)|(raster==22)|(raster==23)|(raster==25)|(raster==27)|(raster==29)|(raster==30)|(raster==31)|(raster==32)|(raster==33)|(raster==34)|(raster==35)|(raster==38)|(raster==39)|(raster==41)|(raster==42)|(raster==43)|(raster==44)|(raster==45)|(raster==46)|(raster==47)|(raster==48)|(raster==49)|(raster==50)|(raster==51)|(raster==52)|(raster==53)|(raster==54)|(raster==55)|(raster==56)|(raster==57)|(raster==58)|(raster==59)|(raster==60)|(raster==61)|(raster==66)|(raster==67)|(raster==68)|(raster==69)|(raster==70)|(raster==71)|(raster==72)|(raster==74)|(raster==75)|(raster==76)|(raster==77)|(raster==204)|(raster==205)|(raster==206)|(raster==207)|(raster==208)|(raster==209)|(raster==210)|(raster==211)|(raster==212)|(raster==213)|(raster==214)|(raster==216)|(raster==217)|(raster==218)|(raster==219)|(raster==220)|(raster==221)|(raster==222)|(raster==223)|(raster==224)|(raster==227)|(raster==229)|(raster==230)|(raster==231)|(raster==232)|(raster==233)|(raster==234)|(raster==235)|(raster==242)|(raster==243)|(raster==244)|(raster==245)|(raster==246)|(raster==247)|(raster==248)|(raster==249)|(raster==250)]<-8
  raster[(raster==24)|(raster==236)|(raster==238)]<-7
  raster[raster==28]<-6
  raster[(raster==5)|(raster==26)|(raster==239)|(raster==240)|(raster==254)]<-2
  raster[(raster==1)|(raster==12)|(raster==13)|(raster==225)|(raster==226)|(raster==237)|(raster==241)]<-1
  raster[raster==176]<-3
  raster[raster==37]<-4
  raster[raster==36]<-5
  raster[(raster==63)|(raster==64)|(raster==65)|(raster==81)|(raster==82)|(raster==83)|(raster==87)|(raster==88)|(raster==92)|(raster==111)|(raster==112)|(raster==121)|(raster==122)|(raster==123)|(raster==124)|(raster==131)|(raster==141)|(raster==142)|(raster==143)|(raster==152)|(raster==190)|(raster==195)]<-9
  return(raster)
}
```

```{r Recoding and stacking of original rasters}
Worth_2011<-f.recode(Worth_2011)
Worth_2012<-f.recode(Worth_2012)
Worth_2013<-f.recode(Worth_2013)
Worth_stack<-stack(Worth_2011,Worth_2012,Worth_2013)
rm(Worth_2011)
rm(Worth_2012)
rm(Worth_2013)
```

```{r Combining 2011-2013 data}
f.evercorn=function(stack){
    #remove transitioning areas
    if((stack[1]==9)|(stack[2]==9)|(stack[3]==9)){9}else{
    #identify plots in which there was ever corn in 2011-2013
    if((stack[1]==1)|(stack[2]==1)|(stack[3]==1)){1}else{0}}}

f.onlycorn=function(raster){if(raster[1]==1){1}else{0}}

Worth_evercorn<-calc(Worth_stack,fun=f.evercorn)
Worth_onlycorn<-calc(Worth_evercorn,fun=f.onlycorn)
```

CPO Algorithm.
Source: "Clustering with Obstacles in Spatial Databases"
Authors: Mohamed A. El-Zawawy and Mohem E. El-Sharkawi

```{r Preprocessing of the data}
#Pre-processing
#Clean-up isolated pixels and fill in 1-2 pixel separations of obstruction polygons
#REASON: this is done to 1) save computation time in the alogorithm to follow 2) remove low corn density areas 3) thicken boundaries

f.cleanup=function(raster){
  nearby<-focal(raster,w=matrix(c(1,1,1,1,0,1,1,1,1),nrow=3,ncol=3),byrow=TRUE)
  raster[(raster==1)&(nearby==0)]<-0
  raster[(raster==0)&(nearby==8)]<-1
  count<-1
  while(count>0){
  left<-focal(raster,w=matrix(c(1,1,0,0,0),nrow=1,ncol=5))
  right<-focal(raster,w=matrix(c(0,0,0,1,1),nrow=1,ncol=5))
  up<-focal(raster,w=matrix(c(1,1,0,0,0),nrow=5,ncol=1))
  down<-focal(raster,w=matrix(c(0,0,0,1,1),nrow=5,ncol=1))
  count<-length(raster[(raster==1)&(((left<2)&(right<2))|((up<2)&(down<2)))])
  raster[(raster==1)&(((left<2)&(right<2))|((up<2)&(down<2)))]<-0
  }
  return(raster)
}

Worth<-f.cleanup(Worth_onlycorn)
par(mfrow=c(2,1),mar=c(1,1,1,1)+0.1)
plot(Worth_onlycorn,maxpixels=2000000)
plot(Worth,maxpixels=2000000)
```

```{r Functions used in miniclustering algorithm}
#function to split a raster into parts for further processing
f.split=function(raster){
  la<-xmax(raster)-xmin(raster)
  lo<-ymax(raster)-ymin(raster)
  d1<-nrow(raster)
  d2<-ncol(raster)

  if(d1>1 & d2>1){
    e_xmin<-vector("list",2)
    e_xmax<-vector("list",2)
    e_ymin<-vector("list",2)
    e_ymax<-vector("list",2)
      for(i in 1:2){
      e_xmin[[i]]<-xmin(raster)+(i-1)*(la/2)
      e_xmax[[i]]<-xmin(raster)+i*(la/2)
      e_ymin[[i]]<-ymin(raster)+(i-1)*(lo/2)
      e_ymax[[i]]<-ymin(raster)+i*(lo/2)
      }
    split<-vector("list",4)
    k<-0
    for(i in 1:2){
      for(j in 1:2){
        k<-k+1
        split[[k]]<-crop(raster,extent(matrix(c(e_xmin[[j]],e_xmax[[j]],e_ymin[[(3-i)]],e_ymax[[(3-i)]]),nrow=2,ncol=2,byrow=TRUE)))
      }
    }
  }else{

  if(d1==1&d2>1){
    e_xmin<-vector("list",2)
    e_xmax<-vector("list",2)
      for(i in 1:2){
        e_xmin[[i]]<-xmin(raster)+(i-1)*(la/2)
        e_xmax[[i]]<-xmin(raster)+i*(la/2)
      }
    split<-vector("list",2)
    k<-0
    for(i in 1:2){
      k<-k+1
      split[[k]]<-crop(raster,extent(matrix(c(e_xmin[[i]],e_xmax[[i]],ymin(raster),ymax(raster)),nrow=2,ncol=2,byrow=TRUE)))
    }
  }else{
    
  if(d1>1&d2==1){
    e_ymin<-vector("list",2)
    e_ymax<-vector("list",2)
      for(i in 1:2){
        e_ymin[[i]]<-ymin(raster)+(i-1)*(lo/2)
        e_ymax[[i]]<-ymin(raster)+i*(lo/2)
      }
    split<-vector("list",2)
    k<-0
      for(i in 1:2){
        k<-k+1
        split[[k]]<-crop(raster,extent(matrix(c(xmin(raster),xmax(raster),e_ymin[[i]],e_ymax[[i]]),nrow=2,ncol=2,byrow=TRUE))) 
      }
  }}}
  return(split)
}

### function to determine the density of a queue element
f.density=function(raster){
  d<-mean(values(raster))
  return(d)}

### function to perform the iterative step

f.iterate=function(q,queue_names,queue_location,miniclusters_location,miniboundaries_location,f.density,f.split){
  #index initialization
  k<-0
  l<-length(list.files(miniclusters_location))/2
  m<-length(list.files(miniboundaries_location))/2
  
  #temporary queue initialization
  temp_names<-list()
  temp_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/temp_queue/"
  if(!(file.exists(temp_location))){dir.create(temp_location)}
  
  #cycle through queue and direct elements accordingly
  foreach(i=1:q,.packages=c("raster","sp"),.inorder=FALSE) %dopar% {element_raster<-raster(queue_names[[i]]) #read in queue element
  density<-f.density(element_raster)
 
    if(density==1){
      l<-l+1+runif(1,0,1)
      miniclusters_name<-paste(miniclusters_location,"minicluster",l,".grd",sep="")
      writeRaster(element_raster,file=miniclusters_name)
      }else{
        
    if(density==0){
      m<-m+1+runif(1,0,1)
      boundaries_name<-paste(miniboundaries_location,"boundary",m,".grd",sep="")
      writeRaster(element_raster,file=boundaries_name)
    }else{
      
      element_split<-f.split(element_raster)
      s<-length(element_split)
      for(i in 1:s){
        k<-k+1+runif(1,0,1)
        temp_name<-paste(temp_location,"queue_raster",k,".grd",sep="")
        writeRaster(element_split[[i]],file=temp_name)
        }}}}
  unlink(queue_location,recursive=TRUE) #clears rasters in queue
  file.rename(temp_location,queue_location) #makes temp_queue the new queue
}
```

```{r Processing of miniclustering algorithm}
#file initialization
queue_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/queue/"
miniclusters_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/miniclusters/"
miniboundaries_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/miniboundaries/"

if(!(file.exists(queue_location))){dir.create(queue_location)}
if(!(file.exists(miniclusters_location))){dir.create(miniclusters_location)}
if(!(file.exists(miniboundaries_location))){dir.create(miniboundaries_location)}

#first step
queue_start<-f.split(Worth) #splits the original raster into quadrants
q<-length(queue_start) #set init length of queue
queue_names<-paste(queue_location,"queue_raster",seq_along(queue_start),".grd",sep="")
for(i in seq_along(queue_start)){writeRaster(queue_start[[i]],file=queue_names[[i]],overwrite=TRUE)} #writes each raster in the queue to file

#iterative step
while(q>0){
registerDoParallel(makeCluster(8))
f.iterate(q,queue_names,queue_location,miniclusters_location,miniboundaries_location,f.density,f.split)
if(length(list.files(queue_location))>0){
  queue_names<-paste(queue_location,list.files(queue_location,pattern=".grd$"),sep="")
  q<-length(queue_names)}else{
    queue_names<-list()
    q<-0}
}

#remove queue folders
unlink(queue_location,recursive=TRUE) #clears rasters in queue
unlink(temp_location,recursive=TRUE) #clears rasters in queue
```

### STEP 2: Combine miniclusters into clusters

```{r Clustering algorithm (joining of miniclusters which share two extent boundaries)}
# STEP 2a: Initial vertical bind

#gathering of the names of the files containing the miniclusters from step 1
miniclusters_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/miniclusters/"
miniclusters_names<-paste(miniclusters_location,list.files(miniclusters_location,pattern=".grd"),sep="")
miniclustersa_names<-paste(miniclusters_location,list.files(miniclusters_location,pattern=".gri"),sep="")

#extracting the extents of each of the minicluster rasters
extent_extract=function(name){extent(raster(name))}
extract_list<-lapply(as.list(miniclusters_names),FUN=extent_extract)

#count the number of miniclusters
num_miniclusters<-length(extract_list)

#derive the extents values for each cluster
miniclusters_extents<-matrix(data=NA,nrow=num_miniclusters,ncol=4)
colnames(miniclusters_extents)<-c("xmin","xmax","ymin","ymax")

xmin_extract=function(extents){extents@xmin}
xmax_extract=function(extents){extents@xmax}
ymin_extract=function(extents){extents@ymin}
ymax_extract=function(extents){extents@ymax}

xmins<-lapply(extract_list,xmin_extract)
xmaxs<-lapply(extract_list,xmax_extract)
ymins<-lapply(extract_list,ymin_extract)
ymaxs<-lapply(extract_list,ymax_extract)

miniclusters_extents[,1]<-unlist(xmins)
miniclusters_extents[,2]<-unlist(xmaxs)
miniclusters_extents[,3]<-unlist(ymins)
miniclusters_extents[,4]<-unlist(ymaxs)

#Determine which pair of miniclusters satisfy the criterion for being joined
a<-Sys.time()
vertical_bind<-list()
registerDoParallel(makeCluster(8))
vertical_bind<-foreach(m=1:num_miniclusters,.packages=c("raster","sp"),.inorder=FALSE) %dopar% {c(m,which((miniclusters_extents[m,1]==miniclusters_extents[,1])&(miniclusters_extents[m,2]==miniclusters_extents[,2])&((miniclusters_extents[m,3]==miniclusters_extents[,4])|(miniclusters_extents[m,4]==miniclusters_extents[,3]))))}
Sys.time()-a

#creates temp file for the results of vertical binding
vertcl_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/vertcl/"
if(!(file.exists(vertcl_location))){dir.create(vertcl_location)}

#Determine which miniclusters are not part of any pair and which are
vertical_bind_lengths<-lapply(vertical_bind,FUN=length)
uncombined<-(which(vertical_bind_lengths==1))
uncombined_filelist<-c(miniclusters_names[uncombined],miniclustersa_names[uncombined])
combined<-(which(vertical_bind_lengths>1))

#Copy unmatched miniclusters to temp file
file.copy(uncombined_filelist,vertcl_location)

#Combine pairs which satisfy the criterion transitively
matching_pairs<-list()
i<-0
while(length(combined)>0){
matching_tree<-vertical_bind[[combined[1]]]
difference<-length(matching_tree)
  while(difference>0){
  m<-length(matching_tree)
  temp_list<-vector("list",m)
  for(j in 1:m){temp_list[[j]]<-vertical_bind[[matching_tree[j]]]}
  matching_tree<-unique(unlist(temp_list))
  difference<-length(matching_tree)-m
  }
matching_tree<-sort(matching_tree)
i<-i+1
matching_pairs[[i]]<-matching_tree
combined<-combined[-which(combined%in%matching_tree)]
}

#Merge each of the matching pairs into an extended raster
merged_raster=function(items){merge(raster(miniclusters_names[[items]]))}

k<-0
registerDoParallel(makeCluster(8))
foreach(i=1:length(matching_pairs),.packages=c("raster","sp"),.inorder=FALSE) %dopar% {
  pair_length<-length(matching_pairs[[i]])
  raster_list<-list()
  for(j in 1:pair_length){raster_list[[j]]<-raster(miniclusters_names[[matching_pairs[[i]][[j]]]])}
  k<-k+1+runif(1,0,1)
  merged_raster<-do.call(merge,raster_list)
  writeRaster(merged_raster,file=paste(vertcl_location,"joinedRaster",k,".grd",sep=""),overwrite=TRUE)
}

#Step 2b: Initial horizontal bind
vertcl_names<-paste(vertcl_location,list.files(vertcl_location,pattern=".grd"),sep="")
vertcla_names<-paste(vertcl_location,list.files(vertcl_location,pattern=".gri"),sep="")

#extracting the extents of each of the minicluster rasters
extent_extract=function(name){extent(raster(name))}
extract_list<-lapply(as.list(vertcl_names),FUN=extent_extract)

#count the number of miniclusters
num_vertclusters<-length(extract_list)
shrinkage<-num_miniclusters-num_vertclusters

#derive the extents values for each cluster
vert_extents<-matrix(data=NA,nrow=num_vertclusters,ncol=4)
colnames(vert_extents)<-c("xmin","xmax","ymin","ymax")

xmin_extract=function(extents){extents@xmin}
xmax_extract=function(extents){extents@xmax}
ymin_extract=function(extents){extents@ymin}
ymax_extract=function(extents){extents@ymax}

xmins<-lapply(extract_list,xmin_extract)
xmaxs<-lapply(extract_list,xmax_extract)
ymins<-lapply(extract_list,ymin_extract)
ymaxs<-lapply(extract_list,ymax_extract)

vert_extents[,1]<-unlist(xmins)
vert_extents[,2]<-unlist(xmaxs)
vert_extents[,3]<-unlist(ymins)
vert_extents[,4]<-unlist(ymaxs)

#Determine which pair of vertclusters satisfy the criterion for being joined
a<-Sys.time()
horizontal_bind<-list()
registerDoParallel(makeCluster(8))
horizontal_bind<-foreach(m=1:num_vertclusters,.packages=c("raster","sp"),.inorder=FALSE) %dopar% {c(m,which((vert_extents[m,3]==vert_extents[,3])&(vert_extents[m,4]==vert_extents[,4])&((vert_extents[m,1]==vert_extents[,2])|(vert_extents[m,2]==vert_extents[,1]))))}
Sys.time()-a

#Creates temp file for the results of the horizontal binding
horcl_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/horcl/"
if(!(file.exists(horcl_location))){dir.create(horcl_location)}

#Determine which vertclusters are not part of any pair and which are
horizontal_bind_lengths<-lapply(horizontal_bind,FUN=length)
uncombined<-(which(horizontal_bind_lengths==1))
uncombined_filelist<-c(vertcl_names[uncombined],vertcla_names[uncombined])
combined<-(which(horizontal_bind_lengths>1))

#Copy unmatched rasters into the temp location
file.copy(uncombined_filelist,horcl_location)

#Combine pairs which satisfy the criterion transitively
matching_pairs<-list()
i<-0
while(length(combined)>0){
matching_tree<-horizontal_bind[[combined[1]]]
difference<-length(matching_tree)
  while(difference>0){
  m<-length(matching_tree)
  temp_list<-vector("list",m)
  for(j in 1:m){temp_list[[j]]<-horizontal_bind[[matching_tree[j]]]}
  matching_tree<-unique(unlist(temp_list))
  difference<-length(matching_tree)-m
  }
matching_tree<-sort(matching_tree)
i<-i+1
matching_pairs[[i]]<-matching_tree
combined<-combined[-which(combined%in%matching_tree)]
}

#Merge each of the matching pairs into an extended raster
merged_raster=function(items){merge(raster(vertcl_names[[items]]))}
k<-length(list.files(horcl_location,pattern=".grd"))

registerDoParallel(makeCluster(8))
foreach(i=1:length(matching_pairs),.packages=c("raster","sp"),.inorder=FALSE) %dopar% {
  pair_length<-length(matching_pairs[[i]])
  raster_list<-list()
  for(j in 1:pair_length){raster_list[[j]]<-raster(vertcl_names[[matching_pairs[[i]][[j]]]])}
  k<-k+1+runif(1,0,1)
  merged_raster<-do.call(merge,raster_list)
  writeRaster(merged_raster,file=paste(horcl_location,"joinedRaster",k,".grd",sep=""),overwrite=TRUE)
}

##Step 2c: Iterative joining##
##############################

while(shrinkage>0){
#####Hor->Vert step
#gathering name of files
horcl_names<-paste(horcl_location,list.files(horcl_location,pattern=".grd"),sep="")
horcla_names<-paste(horcl_location,list.files(horcl_location,pattern=".gri"),sep="")

#extracting the extents of each of the minicluster rasters
extent_extract=function(name){extent(raster(name))}
extract_list<-lapply(as.list(horcl_names),FUN=extent_extract)

#count the number of miniclusters
num_horclusters<-length(extract_list)
shrinkage<-num_vertclusters-num_horclusters
if(shrinkage==0){break}

#derive the extents values for each cluster
hor_extents<-matrix(data=NA,nrow=num_horclusters,ncol=4)
colnames(hor_extents)<-c("xmin","xmax","ymin","ymax")

xmin_extract=function(extents){extents@xmin}
xmax_extract=function(extents){extents@xmax}
ymin_extract=function(extents){extents@ymin}
ymax_extract=function(extents){extents@ymax}

xmins<-lapply(extract_list,xmin_extract)
xmaxs<-lapply(extract_list,xmax_extract)
ymins<-lapply(extract_list,ymin_extract)
ymaxs<-lapply(extract_list,ymax_extract)

hor_extents[,1]<-unlist(xmins)
hor_extents[,2]<-unlist(xmaxs)
hor_extents[,3]<-unlist(ymins)
hor_extents[,4]<-unlist(ymaxs)

#Determine which pair of horclusters satisfy the criterion for being joined
a<-Sys.time()
vertical_bind<-list()
registerDoParallel(makeCluster(8))
vertical_bind<-foreach(m=1:num_horclusters,.packages=c("raster","sp"),.inorder=FALSE) %dopar% {c(m,which((hor_extents[m,1]==hor_extents[,1])&(hor_extents[m,2]==hor_extents[,2])&((hor_extents[m,3]==hor_extents[,4])|(hor_extents[m,4]==hor_extents[,3]))))}
Sys.time()-a

#reset temp file for the results of vertical binding
old_files<-list.files(vertcl_location)
make_filename=function(file){paste(vertcl_location,file,sep="")}
remove_files<-lapply(old_files,FUN=make_filename)
lapply(remove_files,FUN=file.remove)

#Determine which vertclusters are not part of any pair and which are
vertical_bind_lengths<-lapply(vertical_bind,FUN=length)
uncombined<-(which(vertical_bind_lengths==1))
uncombined_filelist<-c(horcl_names[uncombined],horcla_names[uncombined])
combined<-(which(vertical_bind_lengths>1))

#Copy unmatched vertclusters to temp file
file.copy(uncombined_filelist,vertcl_location)

#Combine pairs which satisfy the criterion transitively
matching_pairs<-list()
i<-0
while(length(combined)>0){
matching_tree<-vertical_bind[[combined[1]]]
difference<-length(matching_tree)
  while(difference>0){
  m<-length(matching_tree)
  temp_list<-vector("list",m)
  for(j in 1:m){temp_list[[j]]<-vertical_bind[[matching_tree[j]]]}
  matching_tree<-unique(unlist(temp_list))
  difference<-length(matching_tree)-m
  }
matching_tree<-sort(matching_tree)
i<-i+1
matching_pairs[[i]]<-matching_tree
combined<-combined[-which(combined%in%matching_tree)]
}

#Merge each of the matching pairs into an extended raster
merged_raster=function(items){merge(raster(horcl_names[[items]]))}

k<-0
registerDoParallel(makeCluster(8))
foreach(i=1:length(matching_pairs),.packages=c("raster","sp"),.inorder=FALSE) %dopar% {
  pair_length<-length(matching_pairs[[i]])
  raster_list<-list()
  for(j in 1:pair_length){raster_list[[j]]<-raster(horcl_names[[matching_pairs[[i]][[j]]]])}
  k<-k+1+runif(1,0,1)
  merged_raster<-do.call(merge,raster_list)
  writeRaster(merged_raster,file=paste(vertcl_location,"joinedRaster",k,".grd",sep=""),overwrite=TRUE)
}

#####Vert->Hor step
#gathering name of files
vertcl_names<-paste(vertcl_location,list.files(vertcl_location,pattern=".grd"),sep="")
vertcla_names<-paste(vertcl_location,list.files(vertcl_location,pattern=".gri"),sep="")

#extracting the extents of each of the minicluster rasters
extent_extract=function(name){extent(raster(name))}
extract_list<-lapply(as.list(vertcl_names),FUN=extent_extract)

#count the number of miniclusters
num_vertclusters<-length(extract_list)
shrinkage<-num_horclusters-num_vertclusters
if(shrinkage==0){break}

#derive the extents values for each cluster
vert_extents<-matrix(data=NA,nrow=num_vertclusters,ncol=4)
colnames(vert_extents)<-c("xmin","xmax","ymin","ymax")

xmin_extract=function(extents){extents@xmin}
xmax_extract=function(extents){extents@xmax}
ymin_extract=function(extents){extents@ymin}
ymax_extract=function(extents){extents@ymax}

xmins<-lapply(extract_list,xmin_extract)
xmaxs<-lapply(extract_list,xmax_extract)
ymins<-lapply(extract_list,ymin_extract)
ymaxs<-lapply(extract_list,ymax_extract)

vert_extents[,1]<-unlist(xmins)
vert_extents[,2]<-unlist(xmaxs)
vert_extents[,3]<-unlist(ymins)
vert_extents[,4]<-unlist(ymaxs)

#Determine which pair of vertclusters satisfy the criterion for being joined
a<-Sys.time()
horizontal_bind<-list()
registerDoParallel(makeCluster(8))
horizontal_bind<-foreach(m=1:num_vertclusters,.packages=c("raster","sp"),.inorder=FALSE) %dopar% {c(m,which((vert_extents[m,1]==vert_extents[,1])&(vert_extents[m,2]==vert_extents[,2])&((vert_extents[m,3]==vert_extents[,4])|(vert_extents[m,4]==vert_extents[,3]))))}
Sys.time()-a

#reset temp file for the results of horizontal binding
old_files<-list.files(horcl_location)
make_filename=function(file){paste(horcl_location,file,sep="")}
remove_files<-lapply(old_files,FUN=make_filename)
lapply(remove_files,FUN=file.remove)

#Determine which horclusters are not part of any pair and which are
horizontal_bind_lengths<-lapply(horizontal_bind,FUN=length)
uncombined<-(which(horizontal_bind_lengths==1))
uncombined_filelist<-c(vertcl_names[uncombined],vertcla_names[uncombined])
combined<-(which(horizontal_bind_lengths>1))

#Copy unmatched horclusters to temp file
file.copy(uncombined_filelist,horcl_location)

#Combine pairs which satisfy the criterion transitively
matching_pairs<-list()
i<-0
while(length(combined)>0){
matching_tree<-horizontal_bind[[combined[1]]]
difference<-length(matching_tree)
  while(difference>0){
  m<-length(matching_tree)
  temp_list<-vector("list",m)
  for(j in 1:m){temp_list[[j]]<-horizontal_bind[[matching_tree[j]]]}
  matching_tree<-unique(unlist(temp_list))
  difference<-length(matching_tree)-m
  }
matching_tree<-sort(matching_tree)
i<-i+1
matching_pairs[[i]]<-matching_tree
combined<-combined[-which(combined%in%matching_tree)]
}

#Merge each of the matching pairs into an extended raster
merged_raster=function(items){merge(raster(vertcl_names[[items]]))}

k<-0
registerDoParallel(makeCluster(8))
foreach(i=1:length(matching_pairs),.packages=c("raster","sp"),.inorder=FALSE) %dopar% {
  pair_length<-length(matching_pairs[[i]])
  raster_list<-list()
  for(j in 1:pair_length){raster_list[[j]]<-raster(vertcl_names[[matching_pairs[[i]][[j]]]])}
  k<-k+1+runif(1,0,1)
  merged_raster<-do.call(merge,raster_list)
  writeRaster(merged_raster,file=paste(horcl_location,"joinedRaster",k,".grd",sep=""),overwrite=TRUE)
}
}

clusters_location<-"/Users/goodrich/Desktop/R Projects/Supply.Chain.Development/clusters/"
file.rename(horcl_location,clusters_location) #defines the cluster folder
 
unlink(vertcl_location,recursive=TRUE) #removes temp folder
```
